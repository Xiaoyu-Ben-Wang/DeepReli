## Introduction

The onset of the the COVID-19 pandemic has given the world more to battle. It has faced a barrage of misinformation known as the infodemic. Due to increased restrictions and quarantine, information is trafficked to the public via social media and other digital mediums, allowing misinformation propagation at a large scale .Despite the available public health guidelines online, there is a more insidious presence of misinformation online, comprising ~20% of shared information. An example of a frequently used social media is Twitter, one of the largest social media platforms globally frequently used to share news article, which is known to contain ~25% misinformation. Even though the proportion of shared misinformation is less than evidence-informed guidelines, misinformation also tends to spread faster because it contains more rousing and inflammatory information. Furthermore, another challenge presented to the public is the ability to discern true versus false information. According to the Pew Research Center, around 1 in 4 individuals in the USA are uncertain regarding the truthfulness of the information they received. Hence, we need to construct methods to deter the spread of misinformation online and identify potential sources of misinformation.

Although news organizations and social media companies have implemented measures to flag and delete misinformation, the rate of manual misinformation detection is not fast enough to compete with rapid spread of misinformation. As such, the spread of misinformation and unreliable news has resulted in public confusion regarding trustworthy information, leading to anti-mask and vaccine rhetoric.

Presently, the most common method to detect misinformation online are through human curated fact checking websites like "Snopes" to filter out false information. While this method may be accurate, it is inefficient due to the sheer amount of misinformation generated during the COVID-19 pandemic. Thus, automatic fact checking is needed to detect fake news. Hence, Natural Language Processing (NLP) deep learning models are built to assess large amounts of data to find patterns within reliable and unreliable data, as language use differ between true and false information. As the use of deep learning to identify COVID-19 news article reliability has not been done before, we hope to investigate this topic.

## Approach
Current misinformation detection using machine learning on social media has been researched extensively. Traditional machine learning algorithms are commonly used to detect misinformation within social media sites and news articles. A frequent machine learning algorithm used to detect misinformation is the Support Vector Machine (SVM). Specifically, text features within news articles were used in a SVM to detect conspiratorial messages to predict misinformation to an accuracy of 86%. Another study by Aphiwongsophon and Chongstitvtana analyzed 22 twitter message attributes like the number of retweets and hashtags. They hypothesized that these 22 attributes can predict the truthfulness of a twitter post. Interestingly, with the use of Naive Bayes and SVM, accuracies achieved were 96% and 99.9% respectively which illustrates the importance of using multiple features to predict the truthfulness of a social media message.
In addition to studying the features of a false message itself, it is crucial to investigate the nature of spread in terms of the misinformation. A study by Sahoo et al., examined the relationship between the spread of misinformation and how the degree of spread can be connected back to spam accounts. Their ability to predict whether a twitter account was a spam account using traditional machine learning algorithms like Random Forest to an accuracy of 97-98% shows how the speed of information transfer can be used to predict misinformation, with widespread and faster information transfer being diagnostic of misinformation. Comparatively, there are deep learning approaches in misinformation and reliability classification due to recent advances.

In addition to traditional machine learning algorithms, deep learning tools were also implemented to predict misinformation using large sets of data.
A study by Abdullah et al.,  focused on using Recurrent Neural Networks, a Deep Learning algorithm, to predict misinformation in news articles to an accuracy of 71% using the length of the words as a predictive feature.
Previous studies employing methods similar to our approach include using NLP to detect misinformation include the use of language features like syntax and sentiment, and social context like demographics of the user to determine propaganda in news articles. Or Serrano et al., who proposed applying NLP to detect false information within YouTube comments.Existing NLP methods focuses directly on categorizing information into misinformation and factual information via the detection of key words or phrases from a variety of different media using sentiment analysis. This study is similar to our model as it also uses text and sentiment analysis for classification. However, using singular features such as textual features or sentiment to determine misinformation is limited in representing the complexity of detecting misinformation which can contain multiple aspects. As such, our study of a multi-input model is logical next-step from previous studies and is a potential solution to the multifaceted problem that is misinformation. To our knowledge, a multi-input deep learning approach to news reliability has not been done before. We hope to expand on these previous works by experimenting with features and potential models that have shown to be promising. Through this, we aim to create a deep learning model that is not only supported by recent research but also advances the area of news reliability classification.

## Statistical Analysis and Findings

## Our Solution

## Future Directions